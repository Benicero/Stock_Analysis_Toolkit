Alrighty
========

## basic structure as im thinking so far:
1. scripts to scrape sites
    * read actual data of stocks from somewhere  
        (how often? hourly? daily? and how many/what stocks?)
    * scrape investing sites
2. interpret and store site data
    * store stock data in an efficient format, and make it nicely accessible  
        (we can probably store data on our local machines to save github space)
    * extract investing sites' advice, along with author, date & time
3. analyze data
    * look at basic stock performance data, look for trends and patterns
    * see which investing sites and authors are accurate for which stocks


## other:
* i am thinking it would be good to have basically a "control group" thing that would basically pick random stocks each day, and see how well it does, to get a baseline
